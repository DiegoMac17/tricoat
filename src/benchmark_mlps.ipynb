{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import CLIReporter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce\n",
    "from numpy import squeeze\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor, vstack, cat, mean, std, torch\n",
    "####\n",
    "from all_data_dataset import all_data_dataset\n",
    "from hyperparm_tunning_new_tune import tuner, train\n",
    "from train_test_no_tune import train_test_no_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'path_gwas' : os.path.dirname('~/fast/pd_subtype/data/ad_genes_OR.csv'),\n",
    "    'fn_gwas' : os.path.basename('~/fast/pd_subtype/data/ad_genes_OR.csv'),\n",
    "    'path_snp' : os.path.dirname('../../../../bulk/machad/ADNI/geno/final/adni_wgs_recode.raw'),\n",
    "    'fn_snp' : os.path.basename('../../../../bulk/machad/ADNI/geno/final/adni_wgs_recode.raw'),\n",
    "    'path_clin' : os.path.dirname('../../../../bulk/machad/ADNI/ADNIMERGE.csv'),\n",
    "    'fn_clin' : os.path.basename('../../../../bulk/machad/ADNI/ADNIMERGE.csv'),\n",
    "    'path_img' : os.path.dirname('../../../../bulk/machad/ADNI/imaging/TADPOLE_D1_D2.csv'),\n",
    "    'fn_img' : os.path.basename('../../../../bulk/machad/ADNI/imaging/TADPOLE_D1_D2.csv'),\n",
    "    'path_img_feat':os.path.dirname('../../../../bulk/machad/ADNI/adni_img_feat_names_crossectional.txt'),\n",
    "    'fn_img_feat': os.path.basename('../../../../bulk/machad/ADNI/adni_img_feat_names_crossectional.txt'),\n",
    "    'path_labels':os.path.dirname('~/fast/pd_subtype/results/figures/adni_labels.csv'),\n",
    "    'fn_labels': os.path.basename('~/fast/pd_subtype/results/figures/adni_labels.csv'),\n",
    "    'path_feat_dict' : os.path.dirname('../../../../bulk/machad/ADNI/TADPOLE_D1_D2_Dict.csv'),\n",
    "    'fn_feat_dict' : os.path.basename('../../../../bulk/machad/ADNI/TADPOLE_D1_D2_Dict.csv'), \n",
    "    'path_res' : '../results',\n",
    "    'checkpoint_name' : '../checkpoints'\n",
    "}\n",
    "args = {\n",
    "    'demo_vars' : ['PTID','AGE','PTGENDER','PTETHCAT','PTRACCAT', 'MMSE'],\n",
    "#     'clin_vars' : ['ABETA_bl_UCSFFSL_02_01_16_UCSFFSL51_03_01_22', 'TAU_bl_UCSFFSL_02_01_16_UCSFFSL51_03_01_22', 'PTAU_bl_UCSFFSL_02_01_16_UCSFFSL51_03_01_22', 'FDG_bl_UCSFFSL_02_01_16_UCSFFSL51_03_01_22'],\n",
    "    'clin_vars' : ['RAVLT_immediate' ,'RAVLT_learning' ,'RAVLT_forgetting' ,'RAVLT_perc_forgetting' ,'LDELTOTAL', 'DIGITSCOR', 'TRABSCOR'],\n",
    "    'outcome_vars' : ['MMSE','CDRSB'],\n",
    "    'visits' : ['bl','m06','m12','m24'],\n",
    "    'impute': True,\n",
    "    'visit_colnm' : 'VISCODE',\n",
    "    'tune_flag':False,\n",
    "    'ablation':'rf',\n",
    "    'use_cluster_flag':True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fast/machad/pd_subtype/released/all_data_dataset.py:100: DtypeWarning: Columns (22,23,24,53,54,82,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df_full = pd.read_csv(os.path.join(self.path,self.fn))\n"
     ]
    }
   ],
   "source": [
    "all_inputs = all_data_dataset(paths, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_exp(paths, args, config):\n",
    "    results_dict_all_splits = {}\n",
    "\n",
    "    # Load data\n",
    "    all_inputs = all_data_dataset(paths, args)\n",
    "   \n",
    "    # Generate splits using sklearn\n",
    "    skf_outer = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    # for i, (train_index, test_index) in enumerate(skf_outer.split(all_inputs[:][0], all_inputs[:][3])):\n",
    "    for i, (train_index, test_index) in enumerate(skf_outer.split(np.zeros(len(all_inputs.get_labels())), all_inputs.get_labels())):\n",
    "        results_dict_per_test_set = {}\n",
    "        skf_inner = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "        # for j, (train_index_sub, val_index) in enumerate(skf_inner.split(train_index, all_inputs[train_index][3])):\n",
    "        for j, (train_index_sub, val_index) in enumerate(skf_inner.split(train_index, all_inputs.get_labels(train_index))):\n",
    "            train_index_sub = train_index[train_index_sub]\n",
    "            val_index = train_index[val_index]\n",
    "            assert np.intersect1d(train_index_sub, val_index).size == 0 and np.intersect1d(train_index_sub, test_index).size == 0 and np.intersect1d(val_index, test_index).size == 0 \n",
    "            # Hyperparam tunning (Train - validate)\n",
    "            all_inputs.set_trainset_mean_std(train_index)\n",
    "            all_inputs.normalize_data(train_index_sub, val_index, test_index)\n",
    "            if args['tune_flag']:\n",
    "                results_dict_per_test_set[j] = tuner(all_inputs, train_index_sub, val_index, test_index, paths, args)\n",
    "            else:\n",
    "                results_dict_per_test_set[j] = train_test_no_tune(all_inputs, train_index_sub, val_index, test_index, paths, args, config)\n",
    "        \n",
    "        print('#'*40)\n",
    "        print(f'Finished 5-fold cv on test set: {i}')\n",
    "\n",
    "        results_dict_all_splits[i] = results_dict_per_test_set\n",
    "        \n",
    "    print('#'*40)\n",
    "    print('Finished 10-fold cross testing on test set')\n",
    "    return results_dict_all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =[]\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        metrics.append(pd.DataFrame.from_dict([results_dict_all_splits[i][j]['metrics']]))\n",
    "\n",
    "# TODO: concatenate the metrics dataframe per iteration into 1\n",
    "merged_df = pd.concat(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd_subtype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
