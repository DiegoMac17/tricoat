{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from utils import wgs_cleaner, select_snps, gene_rep, filter_and_imput, clean_pat_wgs_id_ADNI, filter_and_impute_img\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = '../../results/ADNI_raytune_iter_0_results_dictionary.pkl'\n",
    "quant_res_path = '../../results/ADNI_raytune_iter_0_results_summary.csv'\n",
    "clin_feat_path =  '../data/ADNI/adni_clin_feat_names.txt'\n",
    "img_feat_path =  '../data/ADNI/adni_img_roi_names_short.txt'\n",
    "gen_feat_path =  '../data/ADNI/adni_gen_feat_names.txt'\n",
    "clin_dat_path = '../data/ADNI/ADNIMERGE.csv'\n",
    "img_dat_path = '../data/ADNI/imaging/TADPOLE_D1_D2.csv'\n",
    "path_img_feat = '../../../../bulk/machad/ADNI/adni_img_feat_names_crossectional.txt'\n",
    "path_feat_dict = '../../../../bulk/machad/ADNI/TADPOLE_D1_D2_Dict.csv'\n",
    "path_roi_nm = '../../../../bulk/machad/ADNI/adni_img_roi_names.txt'\n",
    "path_img_feat_short = '../data/ADNI/adni_img_roi_names_short.txt'\n",
    "outcome_vars = ['MMSE','CDRSB', 'DX_bl']\n",
    "demo_vars = ['PTID','AGE','PTGENDER','PTETHCAT','PTRACCAT']\n",
    "clin_vars = ['RAVLT_immediate' ,'RAVLT_learning' ,'RAVLT_forgetting' ,'RAVLT_perc_forgetting' ,'LDELTOTAL', 'DIGITSCOR', 'TRABSCOR']\n",
    "impute,vis_colnm = 'True', 'VISCODE'\n",
    "visit = 'bl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all pat data and compute descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_520271/1966219425.py:1: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clin_dat = pd.read_csv(clin_dat_path)\n",
      "/tmp/ipykernel_520271/1966219425.py:2: DtypeWarning: Columns (22,23,24,53,54,82,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  img_data = pd.read_csv(img_dat_path)\n"
     ]
    }
   ],
   "source": [
    "clin_dat = pd.read_csv(clin_dat_path)\n",
    "img_data = pd.read_csv(img_dat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in outcome_vars:\n",
    "    clin_dat = clin_dat[clin_dat[var].notna()]\n",
    "clin_dat.PTID = clin_dat.PTID.apply(lambda x: clean_pat_wgs_id_ADNI(x))\n",
    "clin_dat_bl_demo, clin_dat_bl_x, clin_dat_y  = filter_and_imput(clin_dat,'bl',demo_vars,clin_vars,outcome_vars,impute,vis_colnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_nm = np.loadtxt(path_roi_nm, dtype= 'str').tolist()\n",
    "img_feat_short = np.loadtxt(path_img_feat_short, dtype= 'str').tolist()\n",
    "img_feat_short_map = dict(zip(roi_nm,img_feat_short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feat_nm = np.loadtxt(path_img_feat, dtype= 'str').tolist()\n",
    "cols_interest = img_feat_nm\n",
    "roi_df = pd.read_csv(path_feat_dict, dtype='str')\n",
    "img_data['PTID']\n",
    "img_data['PTID'] = img_data.PTID.apply(lambda x: clean_pat_wgs_id_ADNI(x))\n",
    "img_data = img_data.set_index('PTID')\n",
    "\n",
    "img_data = img_data.loc[img_data[vis_colnm] == visit,:]\n",
    "\n",
    "# drop column for visit ID\n",
    "img_data = img_data[img_data[vis_colnm].notna()]\n",
    "\n",
    "# Filter cols / vars of interest\n",
    "img_data = img_data.loc[:,cols_interest]\n",
    "\n",
    "# Replace empty rows that have ' ' for nan\n",
    "img_data = img_data.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Drop all rows that have all nans for patients\n",
    "img_data = img_data.dropna(axis = 0, how = 'all')\n",
    "\n",
    "# Filter for only Cross-Sectional analysis\n",
    "roi_df = roi_df[roi_df['FLDNAME'].isin(cols_interest)]\n",
    "roi_df = roi_df.loc[roi_df['CRFNAME'] == 'Cross-Sectional FreeSurfer (FreeSurfer Version 4.3)',:]\n",
    "\n",
    "# Parse regions of interest\n",
    "roi_df['ROI'] = roi_df['TEXT'].str.split('of',expand=True).iloc[:,1]\n",
    "roi_df['Trait'] = roi_df['TEXT'].str.split('of',expand=True).iloc[:,0]\n",
    "roi_df['Trait'] =  roi_df['Trait'].replace(r\"^ +| +$\", r\"\", regex=True)\n",
    "roi_df = roi_df.set_index('FLDNAME')\n",
    "roi_shared = roi_df.loc[roi_df['Trait'] == 'Cortical Thickness Average','ROI']\n",
    "idx = img_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data.columns = img_data.columns.map(roi_df.ROI.replace(r\"^ +| +$\", r\"\", regex=True).to_dict()).map(img_feat_short_map)\n",
    "img_data = img_data.loc[:, img_data.columns.notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "      <th>LDELTOTAL</th>\n",
       "      <th>DIGITSCOR</th>\n",
       "      <th>TRABSCOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.522353</td>\n",
       "      <td>4.424471</td>\n",
       "      <td>4.218353</td>\n",
       "      <td>55.292831</td>\n",
       "      <td>7.753875</td>\n",
       "      <td>37.034398</td>\n",
       "      <td>115.413179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.821157</td>\n",
       "      <td>2.784546</td>\n",
       "      <td>2.712804</td>\n",
       "      <td>36.499139</td>\n",
       "      <td>5.472213</td>\n",
       "      <td>8.121238</td>\n",
       "      <td>72.088317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.250025</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>37.034398</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>55.292831</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.034398</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>37.034398</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  \\\n",
       "count      2132.000000     2132.000000       2132.000000   \n",
       "mean         36.522353        4.424471          4.218353   \n",
       "std          12.821157        2.784546          2.712804   \n",
       "min           0.000000       -8.000000        -28.000000   \n",
       "25%          27.000000        2.000000          3.000000   \n",
       "50%          36.000000        4.000000          4.000000   \n",
       "75%          46.000000        6.000000          6.000000   \n",
       "max          71.000000       12.000000         15.000000   \n",
       "\n",
       "       RAVLT_perc_forgetting    LDELTOTAL    DIGITSCOR     TRABSCOR  \n",
       "count            2132.000000  2132.000000  2132.000000  2132.000000  \n",
       "mean               55.292831     7.753875    37.034398   115.413179  \n",
       "std                36.499139     5.472213     8.121238    72.088317  \n",
       "min              -400.000000     0.000000     0.000000     0.000000  \n",
       "25%                26.250025     3.000000    37.034398    66.000000  \n",
       "50%                55.292831     8.000000    37.034398    91.000000  \n",
       "75%               100.000000    12.000000    37.034398   132.000000  \n",
       "max               100.000000    23.000000    80.000000   300.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_dat_bl_x.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../results/ADNI_raytune_iter_0_results_dictionary.pkl', 'rb') as handle:\n",
    "    data = handle.read()\n",
    "d = pickle.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load quantitavie results summary table\n",
    "quant_res = pd.read_csv(quant_res_path)\n",
    "quant_res.auc_test.idxmax()\n",
    "\n",
    "# load feature names\n",
    "clin_feat = np.loadtxt(clin_feat_path, dtype='str').tolist()\n",
    "img_feat = np.loadtxt(img_feat_path, dtype='str').tolist()\n",
    "# gen_feat = np.loadtxt(gen_feat_path, dtype='str', delimiter=\"$\").tolist() # Many gene names are not parsed properly so needed to add fake delimiter to allow for loading\n",
    "gen_feat = np.loadtxt(gen_feat_path, dtype='str').tolist()\n",
    "\n",
    "# find top performing model\n",
    "best_model_idx = quant_res.auc_test.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(best_model_idx)\n",
    "best_model = d[best_model_idx//5][best_model_idx-((best_model_idx//5)*5)]\n",
    "best_model_attributions = best_model['data']['attributions_l_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([64, 7])\n",
      "torch.Size([64, 72, 4])\n",
      "torch.Size([64, 70, 4])\n",
      "torch.Size([37, 7])\n",
      "torch.Size([37, 72, 4])\n",
      "torch.Size([37, 70, 4])\n"
     ]
    }
   ],
   "source": [
    "for i in range (27):\n",
    "    print(d[0][0]['data']['attributions_l_train'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2161,  0.0155, -0.1636, -0.1067, -0.1702, -0.2556,  0.4171],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0]['data']['attributions_l_train'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_names = np.concatenate(((np.asarray(clin_feat)), np.apply_along_axis(lambda d: d[0] + '_' + d[1], 1, np.asarray(list(zip(np.repeat(img_feat,4),['CTA','CTSD','SA','VOL']*len(img_feat))))), np.asarray(gen_feat)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_pat = 7\n",
    "k=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find top-k salient features for patient of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_grads = best_model_attributions[0][rand_pat]\n",
    "img_grads = best_model_attributions[1][rand_pat].flatten()\n",
    "gen_grads = best_model_attributions[2][rand_pat].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = torch.cat((clin_grads, img_grads, gen_grads), dim=0)\n",
    "_, topf_idx = torch.topk(all.abs(),k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAVLT_learn</td>\n",
       "      <td>-0.106919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIGITSCOR</td>\n",
       "      <td>-0.055419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAVLT_immed</td>\n",
       "      <td>-0.037298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RAVLT_forget</td>\n",
       "      <td>-0.016572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RPope_CTA</td>\n",
       "      <td>0.005184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RRAC_CTA</td>\n",
       "      <td>0.005707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RInfTemporal_</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LMedOrbit_CTA</td>\n",
       "      <td>0.008752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.127028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>0.162199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Attribution\n",
       "2    RAVLT_learn    -0.106919\n",
       "3      DIGITSCOR    -0.055419\n",
       "4    RAVLT_immed    -0.037298\n",
       "5   RAVLT_forget    -0.016572\n",
       "9      RPope_CTA     0.005184\n",
       "8       RRAC_CTA     0.005707\n",
       "7  RInfTemporal_     0.006686\n",
       "6  LMedOrbit_CTA     0.008752\n",
       "1      LDELTOTAL     0.127028\n",
       "0       TRABSCOR     0.162199"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(all_feat_names[topf_idx.detach().cpu().numpy()],all[topf_idx].detach().cpu().numpy()),columns=['Feature','Attribution']).sort_values(by='Attribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f55db157e80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.nn.functional import log_softmax\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "y_test = best_model['data']['Pheno_og_test']\n",
    "res = torch.Tensor(best_model['data']['sev_scores_test'])\n",
    "preds = torch.exp(log_softmax(res,dim=1)).max(dim=1)[1]\n",
    "cm = confusion_matrix(y_test, preds, labels=[0,1,2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[0,1,2])\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find patients severity score and values for top-k salient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_sevscore = best_model['data']['sev_scores_test']\n",
    "best_model_pat_idxs = best_model['data']['ids_out_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1911, 0.0863, 0.7226])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[rand_pat]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4657.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_pat_idxs[rand_pat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAVLT_immediate          -23.522000\n",
       "RAVLT_learning            -0.424000\n",
       "RAVLT_forgetting          -2.218000\n",
       "RAVLT_perc_forgetting     -5.293000\n",
       "LDELTOTAL                 -4.754000\n",
       "DIGITSCOR                  0.000398\n",
       "TRABSCOR                 144.587000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_dat_pat = clin_dat_bl_x.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "clin_dat_pat - clin_dat_bl_x.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAVLT_immediate          1.0\n",
       "RAVLT_learning           1.0\n",
       "RAVLT_forgetting         1.0\n",
       "RAVLT_perc_forgetting    1.0\n",
       "LDELTOTAL                1.0\n",
       "DIGITSCOR                5.0\n",
       "TRABSCOR                 4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clin_dat_pat/ clin_dat_bl_x.std()).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPope            115.142\n",
       "RPope             53.983\n",
       "RPope             -0.115\n",
       "RPope             -0.070\n",
       "RRAC             334.060\n",
       "RRAC             159.927\n",
       "RRAC              -0.039\n",
       "RRAC              -0.018\n",
       "RInfTemporal   -3670.165\n",
       "RInfTemporal    -957.678\n",
       "RInfTemporal      -0.221\n",
       "RInfTemporal      -0.118\n",
       "LMedOrbit        291.426\n",
       "LMedOrbit        269.291\n",
       "LMedOrbit         -0.106\n",
       "LMedOrbit         -0.153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data_pat = img_data.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "img_data_pat_diff = img_data_pat.astype('float') - img_data.astype('float').mean().round(3)\n",
    "img_data_pat_diff.loc[['RPope', 'RRAC','RInfTemporal','LMedOrbit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPope            5.0\n",
       "RPope            6.0\n",
       "RPope           12.0\n",
       "RPope            7.0\n",
       "RRAC             5.0\n",
       "RRAC             5.0\n",
       "RRAC            10.0\n",
       "RRAC             5.0\n",
       "RInfTemporal     3.0\n",
       "RInfTemporal     4.0\n",
       "RInfTemporal    11.0\n",
       "RInfTemporal     8.0\n",
       "LMedOrbit        5.0\n",
       "LMedOrbit        6.0\n",
       "LMedOrbit       11.0\n",
       "LMedOrbit        6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_data_pat.astype('float') / img_data.astype('float').std()).round(0).loc[['RPope', 'RRAC','RInfTemporal','LMedOrbit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1911, 0.0863, 0.7226])\n",
      "4657.0\n"
     ]
    }
   ],
   "source": [
    "### pat 2 \n",
    "rand_pat = 1\n",
    "k=10\n",
    "clin_grads = best_model_attributions[0][rand_pat]\n",
    "img_grads = best_model_attributions[1][rand_pat].flatten()\n",
    "gen_grads = best_model_attributions[2][rand_pat].flatten()\n",
    "\n",
    "all = torch.cat((clin_grads, img_grads, gen_grads), dim=0)\n",
    "_, topf_idx = torch.topk(all.abs(),k)\n",
    "print(torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[rand_pat]), dim=0))\n",
    "print(best_model_pat_idxs[rand_pat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAVLT_immed</td>\n",
       "      <td>-0.223741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>-0.158018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVLT_forget</td>\n",
       "      <td>-0.134824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAVLT_learn</td>\n",
       "      <td>-0.057594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIGITSCOR</td>\n",
       "      <td>-0.057404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RIC_VOL</td>\n",
       "      <td>0.005377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RCuneus_CTA</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LPorb_CTA</td>\n",
       "      <td>0.006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LFpole_CTA</td>\n",
       "      <td>0.006576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>0.183464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Attribution\n",
       "0   RAVLT_immed    -0.223741\n",
       "2     LDELTOTAL    -0.158018\n",
       "3  RAVLT_forget    -0.134824\n",
       "4   RAVLT_learn    -0.057594\n",
       "5     DIGITSCOR    -0.057404\n",
       "9       RIC_VOL     0.005377\n",
       "8   RCuneus_CTA     0.005764\n",
       "7     LPorb_CTA     0.006029\n",
       "6    LFpole_CTA     0.006576\n",
       "1      TRABSCOR     0.183464"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(all_feat_names[topf_idx.detach().cpu().numpy()],all[topf_idx].detach().cpu().numpy()),columns=['Feature','Attribution']).sort_values(by='Attribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAVLT_immediate          -23.522000\n",
       "RAVLT_learning            -0.424000\n",
       "RAVLT_forgetting          -2.218000\n",
       "RAVLT_perc_forgetting     -5.293000\n",
       "LDELTOTAL                 -4.754000\n",
       "DIGITSCOR                  0.000398\n",
       "TRABSCOR                 144.587000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_dat_pat = clin_dat_bl_x.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "clin_dat_pat - clin_dat_bl_x.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAVLT_immediate          1.0\n",
       "RAVLT_learning           1.0\n",
       "RAVLT_forgetting         1.0\n",
       "RAVLT_perc_forgetting    1.0\n",
       "LDELTOTAL                1.0\n",
       "DIGITSCOR                5.0\n",
       "TRABSCOR                 4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clin_dat_pat/ clin_dat_bl_x.std()).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIC_VOL          -0.103\n",
       "RCuneus_CTA      22.933\n",
       "LPorb_CTA      -471.000\n",
       "LFpole_CTA    -1639.586\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.columns = np.apply_along_axis(lambda d: d[0] + '_' + d[1], 1, np.asarray(list(zip(np.repeat(img_feat,4),['CTA','CTSD','SA','VOL']*len(img_feat)))))\n",
    "img_data_pat = img_data.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "img_data_pat_diff = img_data_pat.astype('float') - img_data.astype('float').mean().round(3)\n",
    "img_data_pat_diff.loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIC_VOL        5.0\n",
       "RCuneus_CTA    6.0\n",
       "LPorb_CTA      6.0\n",
       "LFpole_CTA     5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_data_pat.astype('float') / img_data.astype('float').std()).round(0).loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5310, 0.0799, 0.3891])\n",
      "1249.0\n"
     ]
    }
   ],
   "source": [
    "### pat 3\n",
    "rand_pat = 27\n",
    "k=10\n",
    "clin_grads = best_model_attributions[0][rand_pat]\n",
    "img_grads = best_model_attributions[1][rand_pat].flatten()\n",
    "gen_grads = best_model_attributions[2][rand_pat].flatten()\n",
    "\n",
    "all = torch.cat((clin_grads, img_grads, gen_grads), dim=0)\n",
    "_, topf_idx = torch.topk(all.abs(),k)\n",
    "print(torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[rand_pat]), dim=0))\n",
    "print(best_model_pat_idxs[rand_pat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>-0.082519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LPorb_CTA</td>\n",
       "      <td>-0.005392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RPT_CTSD</td>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RRAC_CTA</td>\n",
       "      <td>0.006913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DIGITSCOR</td>\n",
       "      <td>0.015146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RAVLT_pforget</td>\n",
       "      <td>0.025046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVLT_immed</td>\n",
       "      <td>0.084306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.109818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAVLT_forget</td>\n",
       "      <td>0.122818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAVLT_learn</td>\n",
       "      <td>0.126077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Attribution\n",
       "4       TRABSCOR    -0.082519\n",
       "9      LPorb_CTA    -0.005392\n",
       "8       RPT_CTSD     0.005793\n",
       "7       RRAC_CTA     0.006913\n",
       "6      DIGITSCOR     0.015146\n",
       "5  RAVLT_pforget     0.025046\n",
       "3    RAVLT_immed     0.084306\n",
       "2      LDELTOTAL     0.109818\n",
       "1   RAVLT_forget     0.122818\n",
       "0    RAVLT_learn     0.126077"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(all_feat_names[topf_idx.detach().cpu().numpy()],all[topf_idx].detach().cpu().numpy()),columns=['Feature','Attribution']).sort_values(by='Attribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAVLT_immediate          10.4780\n",
       "RAVLT_learning            4.5760\n",
       "RAVLT_forgetting          3.7820\n",
       "RAVLT_perc_forgetting     1.8499\n",
       "LDELTOTAL                 6.2460\n",
       "DIGITSCOR                 2.9660\n",
       "TRABSCOR                -54.4130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_dat_pat = clin_dat_bl_x.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "clin_dat_pat - clin_dat_bl_x.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LPorb_CTA   -1392.000\n",
       "RPT_CTSD      204.913\n",
       "RRAC_CTA    -2575.956\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.columns = np.apply_along_axis(lambda d: d[0] + '_' + d[1], 1, np.asarray(list(zip(np.repeat(img_feat,4),['CTA','CTSD','SA','VOL']*len(img_feat)))))\n",
    "img_data_pat = img_data.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "img_data_pat_diff = img_data_pat.astype('float') - img_data.astype('float').mean().round(3)\n",
    "img_data_pat_diff.loc[['LPorb_CTA', 'RPT_CTSD','RRAC_CTA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt building\n",
    "prompt = f\"A patient has an overall risk score of {0.7226}, in the range of 0 to 1, of having Alzheimer's disease.\\\n",
    "    A multimodal deep learning model has attributed the high risk of Alzheimer’s disease to several salient features.\\\n",
    "    First, the volume of the right insula with an attribution of {0.005377}, and cortical average thickness of the\\\n",
    "    right cuneus (attribution of {0.005764}), the left pars orbitalis (attribution of {0.006029}), and left frontal pole\\\n",
    "    (attribution of {0.006576}), trails making test B (attribution of {0.183464}), Rey Auditory Verbal Learning test (attribution of 0.057594),\\\n",
    "    digit symbol substitution test (attribution of {0.057404}), and the logical memory - delayed test (attribution of {0.158018}).\\\n",
    "    The patient has a volume of the right insula {5} standard deviations lower than the general population.\\\n",
    "    A {6} standard deviations higher cortical average thickness of the right cuneus, {6} standard deviations\\\n",
    "    lower cortical average thickness of the left pars orbitalis, and {5} standard deviations lower left frontal pole compared to the general population.\\\n",
    "    The patient scored {4} standard deviation higher in the Trails making test B compared to the general population.\\\n",
    "    The patient scored {1} standard deviations lower in the Rey Auditory Verbal Learning test, {5} standard deviations lower digit symbol substitution test,\\\n",
    "    and {1} standard deviation the logical memory - delayed test compared to the general population. Explain how the salient features relate to one another\\\n",
    "    and how they relate to the higher risk of having Alzheimer’s disease. If any of those features is irrelevant to AD, please point it out.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"A patient has an overall risk score of {ad_risk}, in the range of 0 to 1, of having Alzheimer's disease. \\\n",
    "    A multimodal deep learning model has attributed the high risk of Alzheimer’s disease to several salient features. \\\n",
    "    First, the {f1_name} with an attribution of {f1_atr}, and {f2_name} \\\n",
    "    (attribution of {f2_atr}), the {f3_name} (attribution of {f3_atr}), and {f4_name} \\\n",
    "    (attribution of {f4_atr}), {f5_name} (attribution of {f5_atr}), {f6_name} (attribution of {f6_atr}), \\\n",
    "    {f7_name} (attribution of {f7_atr}), and {f8_name} (attribution of {f8_atr}). \\\n",
    "    The patient has a {f1_name} {f1_sd} standard deviations {f1_hilo} than the general population. \\\n",
    "    A {f2_sd} standard deviations {f2_hilo} {f2_name}, {f3_sd} standard deviations \\\n",
    "    {f3_hilo} {f3_name}, and {f4_sd} standard deviations {f4_hilo} {f4_name} compared to the general population. \\\n",
    "    The patient scored {f5_sd} standard deviation {f5_hilo} in the {f5_name} compared to the general population. \\\n",
    "    The patient scored {f6_sd} standard deviations {f6_hilo} in the {f6_name}, {f7_sd} standard deviations {f7_hilo} {f7_name}, \\\n",
    "    and {f8_sd} standard deviation {f8_hilo} the {f8_name} compared to the general population. Explain how the salient features relate to one another \\\n",
    "    and how they relate to the higher risk of having Alzheimer’s disease. If any of those features is irrelevant to AD, please point it out.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hilo(diff):\n",
    "    if diff >0:\n",
    "        return 'higher'\n",
    "    else:\n",
    "        return 'lower' \n",
    "\n",
    "clin_name_dict = {\n",
    "    'RAVLT_immediate':'Rey auditory verbal learning immediate test',\n",
    "    'RAVLT_learning':'Rey auditory verbal learning test',\n",
    "    'RAVLT_forgetting':'Rey auditory verbal learning forgetting test',\n",
    "    'RAVLT_perc_forgetting':'Rey auditory verbal learning percent forgetting test',\n",
    "    'LDELTOTAL':'Logical Memory - Delayed Recall',\n",
    "    'DIGITSCOR':'Digit Symbol Substitution',\n",
    "    'TRABSCOR':'Trail Making Test B',\n",
    "}   \n",
    "img_name_dict = {\n",
    "    'LBankssts': 'Left Cortical areas around superior temporal sulcus',\n",
    "    'LCAC': 'Left Caudal Anterior Cingulate',\n",
    "    'LCMF': 'Left Caudal Middle Frontal',\n",
    "    'LCC': 'Left Corpus Callosum',\n",
    "    'LCuneus': 'Left Cuneus cortex',\n",
    "    'LEntorhinal': 'Left Entorhinal cortex',\n",
    "    'LFpole': 'Left Frontal Pole',\n",
    "    'LFusiform': 'Left Fusiform gyrus',\n",
    "    'LInfParietal': 'Left Inferior Parietal lobe',\n",
    "    'LInfTemporal': 'Left Inferior Temporal gyrus',\n",
    "    'LInsula': 'Left Insula',\n",
    "    'LIC': 'Left Isthmus Cingulate cortex',\n",
    "    'LLatOcc': 'Left Lateral Occipital cortex',\n",
    "    'LLatOrbit': 'Left Lateral Orbitofrontal cortex',\n",
    "    'LLingual': 'Left Lingual gyrus',\n",
    "    'LMedOrbit': 'Left Medial Orbital frontal cortex',\n",
    "    'LMidTemporal': 'Left Middle Temporal gyrus',\n",
    "    'LParacentral': 'Left Paracentral lobule',\n",
    "    'LPH': 'Left Parahippocampal gyrus',\n",
    "    'LPope': 'Left Pars Opercularis',\n",
    "    'LPorb': 'Left Pars Orbitalis',\n",
    "    'LPT': 'Left Pars Triangularis',\n",
    "    'LPC': 'Left Pericalcarine cortex',\n",
    "    'LPostCentral': 'Left Postcentral gyrus',\n",
    "    'LPostCing': 'Left Posterior Cingulate cortex',\n",
    "    'LPrecentral': 'Left Precentral gyrus',\n",
    "    'LPrecuneus': 'Left Precuneus cortex',\n",
    "    'LRAC': 'Left Rostral Anterior Cingulate cortex',\n",
    "    'LRMF': 'Left Rostral Middle Frontal gyrus',\n",
    "    'LSF': 'Left Superior Frontal gyrus',\n",
    "    'LSP': 'Left Superior Parietal gyrus',\n",
    "    'LST': 'Left Superior Temporal gyrus',\n",
    "    'LSMarg': 'Left Supramarginal gyrus',\n",
    "    'LTempPole': 'Left Temporal Pole',\n",
    "    'LTransTemp': 'Left Transverse Temporal cortex',\n",
    "    'RBankssts': 'Right Cortical areas around superior temporal sulcus',\n",
    "    'RCAC': 'Right Caudal Anterior Cingulate',\n",
    "    'RCMF': 'Right Caudal Middle Frontal',\n",
    "    'RCC': 'Right Corpus Callosum',\n",
    "    'RCuneus': 'Right Cuneus cortex',\n",
    "    'REntorhinal': 'Right Entorhinal cortex',\n",
    "    'RFpole': 'Right Frontal Pole',\n",
    "    'RFusiform': 'Right Fusiform gyrus',\n",
    "    'RInfParietal': 'Right Inferior Parietal lobe',\n",
    "    'RInfTemporal': 'Right Inferior Temporal gyrus',\n",
    "    'RInsula': 'Right Insula',\n",
    "    'RIC': 'Right Isthmus Cingulate cortex',\n",
    "    'RLatOcc': 'Right Lateral Occipital cortex',\n",
    "    'RLatOrbit': 'Right Lateral Orbitofrontal cortex',\n",
    "    'RLingual': 'Right Lingual gyrus',\n",
    "    'RMedOrbit': 'Right Medial Orbital frontal cortex',\n",
    "    'RMidTemporal': 'Right Middle Temporal gyrus',\n",
    "    'RParacentral':'Right Paracentral lobule',\n",
    "    'RPH':'Right Parahippocampal gyrus',\n",
    "    'RPope':'Right Pars Opercularis',\n",
    "    'RPorb':'Right Pars Orbitalis',\n",
    "    'RPT':'Right Pars Triangularis',\n",
    "    'RPC':'Right Pericalcarine cortex',\n",
    "    'RPostCentral':'Right Postcentral gyrus',\n",
    "    'RPostCing':'Right Posterior Cingulate cortex',\n",
    "    'RPrecentral':'Right Precentral gyrus',\n",
    "    'RPrecuneus':'Right Precuneus cortex',\n",
    "    'RRAC':'Right Rostral Anterior Cingulate cortex',\n",
    "    'RRMF':'Right Rostral Middle Frontal gyrus',\n",
    "    'RSF':'Right Superior Frontal gyrus',\n",
    "    'RSP':'Right Superior Parietal gyrus',\n",
    "    'RST':'Right Superior Temporal gyrus',\n",
    "    'RSMarg':'Right Supramarginal gyrus',\n",
    "    'RTempPole':'Right Temporal Pole',\n",
    "    'RTransTemp':'Right Transverse Temporal cortex',\n",
    "}\n",
    "struct_name_dict = {\n",
    "    'CTA':'average cortical thickness',\n",
    "    'CTS': 'standard deviation cortical thickness',\n",
    "    'SA':'surface area',\n",
    "    'VOL':'volume'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pat_feats(pat_num,k,best_model_attributions,best_model_sevscore,best_model_pat_idxs,all_feat_names,clin_dat_bl_x):\n",
    "    clin_grads = best_model_attributions[0][pat_num]\n",
    "    img_grads = best_model_attributions[1][pat_num].flatten()\n",
    "    gen_grads = best_model_attributions[2][pat_num].flatten()\n",
    "\n",
    "    all = torch.cat((clin_grads, img_grads, gen_grads), dim=0)\n",
    "    _, topf_idx = torch.topk(all.abs(),k)\n",
    "    print(torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[pat_num]), dim=0))\n",
    "    print(best_model_pat_idxs[pat_num])\n",
    "\n",
    "    salient_feats = pd.DataFrame(zip(all_feat_names[topf_idx.detach().cpu().numpy()],all[topf_idx].detach().cpu().numpy()),columns=['Feature','Attribution']).sort_values(by='Attribution')\n",
    "    clin_dat_pat = clin_dat_bl_x.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "    raw_pat_diff_clin = clin_dat_pat - clin_dat_bl_x.mean().round(3)\n",
    "    sd_pat_clin = (clin_dat_pat/ clin_dat_bl_x.std()).round(0)\n",
    "    img_data.columns = np.apply_along_axis(lambda d: d[0] + '_' + d[1], 1, np.asarray(list(zip(np.repeat(img_feat,4),['CTA','CTSD','SA','VOL']*len(img_feat)))))\n",
    "    img_data_pat = img_data.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "    img_data_pat_diff = img_data_pat.astype('float') - img_data.astype('float').mean().round(3)\n",
    "    raw_pat_diff_img = img_data_pat_diff.loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]\n",
    "    sd_pat_img = (img_data_pat.astype('float') / img_data.astype('float').std()).round(0).loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]\n",
    "\n",
    "    sd_pat_clin.index = sd_pat_clin.index.map(clin_name_dict)\n",
    "    # sd_pat_img.index = sd_pat_img.index.map(img_name_dict)\n",
    "    sd_pat_img['roi'] = sd_pat_img.index.str.split('_').str[0].map(img_name_dict)\n",
    "    sd_pat_img['struct'] = sd_pat_img.index.str.split('_').str[1].map(struct_name_dict)\n",
    "\n",
    "    ad_risk = torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[pat_num]), dim=0)[-1]\n",
    "    print(sd_pat_img)\n",
    "    f1_name, f1_atr, f1_hilo, f1_sd = sd_pat_img[0,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[0,0],'Attribution'],hilo(raw_pat_diff_img[0,1]),sd_pat_img[0,1]\n",
    "    f2_name, f2_atr, f2_hilo, f2_sd = sd_pat_img[1,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[1,0],'Attribution'],hilo(raw_pat_diff_img[1,1]),sd_pat_img[1,1]\n",
    "    f3_name, f3_atr, f3_hilo, f3_sd = sd_pat_img[2,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[2,0],'Attribution'],hilo(raw_pat_diff_img[2,1]),sd_pat_img[2,1]\n",
    "    f4_name, f4_atr, f4_hilo, f4_sd = sd_pat_img[3,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[3,0],'Attribution'],hilo(raw_pat_diff_img[3,1]),sd_pat_img[3,1]\n",
    "    f5_name, f5_atr, f5_hilo, f5_sd = sd_pat_img[4,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[4,0],'Attribution'],hilo(raw_pat_diff_img[4,1]),sd_pat_img[4,1]\n",
    "    f6_name, f6_atr, f6_hilo, f6_sd = sd_pat_img[5,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[5,0],'Attribution'],hilo(raw_pat_diff_img[5,1]),sd_pat_img[5,1]\n",
    "    f7_name, f7_atr, f7_hilo, f7_sd = sd_pat_img[6,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[6,0],'Attribution'],hilo(raw_pat_diff_img[6,1]),sd_pat_img[6,1]\n",
    "    f8_name, f8_atr, f8_hilo, f8_sd = sd_pat_img[7,0],salient_feats.loc[salient_feats['Feature']==sd_pat_img[7,0],'Attribution'],hilo(raw_pat_diff_img[7,1]),sd_pat_img[7,1]\n",
    "\n",
    "\n",
    "    prompt = f\"A patient has an overall risk score of {ad_risk}, in the range of 0 to 1, of having Alzheimer's disease. \\\n",
    "    A multimodal deep learning model has attributed the high risk of Alzheimer’s disease to several salient features. \\\n",
    "    First, the {f1_name} with an attribution of {f1_atr}, and {f2_name} \\\n",
    "    (attribution of {f2_atr}), the {f3_name} (attribution of {f3_atr}), and {f4_name} \\\n",
    "    (attribution of {f4_atr}), {f5_name} (attribution of {f5_atr}), {f6_name} (attribution of {f6_atr}), \\\n",
    "    {f7_name} (attribution of {f7_atr}), and {f8_name} (attribution of {f8_atr}). \\\n",
    "    The patient has a {f1_name} {f1_sd} standard deviations {f1_hilo} than the general population. \\\n",
    "    A {f2_sd} standard deviations {f2_hilo} {f2_name}, {f3_sd} standard deviations \\\n",
    "    {f3_hilo} {f3_name}, and {f4_sd} standard deviations {f4_hilo} {f4_name} compared to the general population. \\\n",
    "    The patient scored {f5_sd} standard deviation {f5_hilo} in the {f5_name} compared to the general population. \\\n",
    "    The patient scored {f6_sd} standard deviations {f6_hilo} in the {f6_name}, {f7_sd} standard deviations {f7_hilo} {f7_name}, \\\n",
    "    and {f8_sd} standard deviation {f8_hilo} the {f8_name} compared to the general population. Explain how the salient features relate to one another \\\n",
    "    and how they relate to the higher risk of having Alzheimer’s disease. If any of those features is irrelevant to AD, please point it out.\"\n",
    "\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3532, 0.0666, 0.5803])\n",
      "802.0\n",
      "volume of the Right Isthmus Cingulate cortex             5.0\n",
      "average cortical thickness of the Right Cuneus cortex    3.0\n",
      "average cortical thickness of the Left Pars Orbitalis    5.0\n",
      "average cortical thickness of the Left Frontal Pole      6.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m f3_name, f3_atr, f3_hilo, f3_sd \u001b[39m=\u001b[39m sd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m2\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m2\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m2\u001b[39m]),sd_pat_img[\u001b[39m2\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m f4_name, f4_atr, f4_hilo, f4_sd \u001b[39m=\u001b[39m sd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m3\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m3\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m3\u001b[39m]),sd_pat_img[\u001b[39m3\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m f5_name, f5_atr, f5_hilo, f5_sd \u001b[39m=\u001b[39m sd_pat_img\u001b[39m.\u001b[39;49mindex[\u001b[39m4\u001b[39;49m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m4\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m4\u001b[39m]),sd_pat_img[\u001b[39m4\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m f6_name, f6_atr, f6_hilo, f6_sd \u001b[39m=\u001b[39m sd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m5\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m5\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m5\u001b[39m]),sd_pat_img[\u001b[39m5\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m f7_name, f7_atr, f7_hilo, f7_sd \u001b[39m=\u001b[39m sd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m6\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img\u001b[39m.\u001b[39mindex[\u001b[39m6\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m6\u001b[39m]),sd_pat_img[\u001b[39m6\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pd_subtype/lib/python3.10/site-packages/pandas/core/indexes/base.py:5053\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5050\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5051\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5052\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 5053\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m   5056\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5057\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5058\u001b[0m     result \u001b[39m=\u001b[39m getitem(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "pat_num = 0\n",
    "clin_grads = best_model_attributions[0][pat_num]\n",
    "img_grads = best_model_attributions[1][pat_num].flatten()\n",
    "gen_grads = best_model_attributions[2][pat_num].flatten()\n",
    "\n",
    "all = torch.cat((clin_grads, img_grads, gen_grads), dim=0)\n",
    "_, topf_idx = torch.topk(all.abs(),k)\n",
    "print(torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[pat_num]), dim=0))\n",
    "print(best_model_pat_idxs[pat_num])\n",
    "\n",
    "salient_feats = pd.DataFrame(zip(all_feat_names[topf_idx.detach().cpu().numpy()],all[topf_idx].detach().cpu().numpy()),columns=['Feature','Attribution']).sort_values(by='Attribution')\n",
    "clin_dat_pat = clin_dat_bl_x.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "raw_pat_diff_clin = clin_dat_pat - clin_dat_bl_x.mean().round(3)\n",
    "sd_pat_clin = (clin_dat_pat/ clin_dat_bl_x.std()).round(0)\n",
    "img_data.columns = np.apply_along_axis(lambda d: d[0] + '_' + d[1], 1, np.asarray(list(zip(np.repeat(img_feat,4),['CTA','CTSD','SA','VOL']*len(img_feat)))))\n",
    "img_data_pat = img_data.loc[str(int(best_model_pat_idxs[rand_pat]))]\n",
    "img_data_pat_diff = img_data_pat.astype('float') - img_data.astype('float').mean().round(3)\n",
    "raw_pat_diff_img = img_data_pat_diff.loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]\n",
    "sd_pat_img = (img_data_pat.astype('float') / img_data.astype('float').std()).round(0).loc[['RIC_VOL', 'RCuneus_CTA','LPorb_CTA','LFpole_CTA']]\n",
    "\n",
    "sd_pat_clin.index = sd_pat_clin.index.map(clin_name_dict)\n",
    "sd_pat_img.index = pd.Series(sd_pat_img.index.str.split('_').str[1].map(struct_name_dict) +' of the ' + sd_pat_img.index.str.split('_').str[0].map(img_name_dict))\n",
    "# sd_pat_img['roi'] = sd_pat_img.index.str.split('_').str[0].map(img_name_dict)\n",
    "# sd_pat_img['struct'] = sd_pat_img.index.str.split('_').str[1].map(struct_name_dict)\n",
    "\n",
    "ad_risk = torch.nn.functional.softmax(torch.Tensor(best_model_sevscore[pat_num]), dim=0)[-1]\n",
    "print(sd_pat_img)\n",
    "f1_name, f1_atr, f1_hilo, f1_sd = sd_pat_img.index[0],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[0],'Attribution'],hilo(raw_pat_diff_img[0]),sd_pat_img[0]\n",
    "f2_name, f2_atr, f2_hilo, f2_sd = sd_pat_img.index[1],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[1],'Attribution'],hilo(raw_pat_diff_img[1]),sd_pat_img[1]\n",
    "f3_name, f3_atr, f3_hilo, f3_sd = sd_pat_img.index[2],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[2],'Attribution'],hilo(raw_pat_diff_img[2]),sd_pat_img[2]\n",
    "f4_name, f4_atr, f4_hilo, f4_sd = sd_pat_img.index[3],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[3],'Attribution'],hilo(raw_pat_diff_img[3]),sd_pat_img[3]\n",
    "f5_name, f5_atr, f5_hilo, f5_sd = sd_pat_img.index[4],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[4],'Attribution'],hilo(raw_pat_diff_img[4]),sd_pat_img[4]\n",
    "f6_name, f6_atr, f6_hilo, f6_sd = sd_pat_img.index[5],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[5],'Attribution'],hilo(raw_pat_diff_img[5]),sd_pat_img[5]\n",
    "f7_name, f7_atr, f7_hilo, f7_sd = sd_pat_img.index[6],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[6],'Attribution'],hilo(raw_pat_diff_img[6]),sd_pat_img[6]\n",
    "f8_name, f8_atr, f8_hilo, f8_sd = sd_pat_img.index[7],salient_feats.loc[salient_feats['Feature']==sd_pat_img.index[7],'Attribution'],hilo(raw_pat_diff_img[7]),sd_pat_img[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_pat_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3532, 0.0666, 0.5803])\n",
      "802.0\n",
      "RIC_VOL                                                      5.0\n",
      "RCuneus_CTA                                                  3.0\n",
      "LPorb_CTA                                                    5.0\n",
      "LFpole_CTA                                                   6.0\n",
      "roi            Index(['Right Isthmus Cingulate cortex', 'Righ...\n",
      "struct         Index([                    'volume', 'average ...\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m calc_pat_feats(\u001b[39m0\u001b[39;49m,\u001b[39m10\u001b[39;49m,best_model_attributions,best_model_sevscore,best_model_pat_idxs,all_feat_names,clin_dat_bl_x)\n",
      "\u001b[1;32m/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb Cell 44\u001b[0m in \u001b[0;36mcalc_pat_feats\u001b[0;34m(pat_num, k, best_model_attributions, best_model_sevscore, best_model_pat_idxs, all_feat_names, clin_dat_bl_x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m ad_risk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(torch\u001b[39m.\u001b[39mTensor(best_model_sevscore[pat_num]), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(sd_pat_img)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m f1_name, f1_atr, f1_hilo, f1_sd \u001b[39m=\u001b[39m sd_pat_img[\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]),sd_pat_img[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m f2_name, f2_atr, f2_hilo, f2_sd \u001b[39m=\u001b[39m sd_pat_img[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]),sd_pat_img[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbliz.bme.rpi.edu/home/machad/fast/pd_subtype/released/gradient_analysis.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m f3_name, f3_atr, f3_hilo, f3_sd \u001b[39m=\u001b[39m sd_pat_img[\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m],salient_feats\u001b[39m.\u001b[39mloc[salient_feats[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39msd_pat_img[\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mAttribution\u001b[39m\u001b[39m'\u001b[39m],hilo(raw_pat_diff_img[\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m]),sd_pat_img[\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pd_subtype/lib/python3.10/site-packages/pandas/core/series.py:984\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    981\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m--> 984\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/pd_subtype/lib/python3.10/site-packages/pandas/core/series.py:999\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    995\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing a Series with DataFrame is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    996\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported, use the appropriate DataFrame column\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    997\u001b[0m     )\n\u001b[1;32m    998\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 999\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values_tuple(key)\n\u001b[1;32m   1001\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key):\n\u001b[1;32m   1002\u001b[0m     \u001b[39m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/pd_subtype/lib/python3.10/site-packages/pandas/core/series.py:1034\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m   1033\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m-> 1034\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1036\u001b[0m \u001b[39m# If key is contained, would have returned by now\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m indexer, new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc_level(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "calc_pat_feats(0,10,best_model_attributions,best_model_sevscore,best_model_pat_idxs,all_feat_names,clin_dat_bl_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_build(blanks):\n",
    "    ad_risk = blanks[]\n",
    "    f1_name, f1_atr, f1_hilo, f1_sd = blanks['f1_name'],blanks[],blanks[],blanks[]\n",
    "    f2_name, f2_atr, f2_hilo, f2_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f3_name, f3_atr, f3_hilo, f3_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f4_name, f4_atr, f4_hilo, f4_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f5_name, f5_atr, f5_hilo, f5_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f6_name, f6_atr, f6_hilo, f6_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f7_name, f7_atr, f7_hilo, f7_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    f8_name, f8_atr, f8_hilo, f8_sd = blanks[],blanks[],blanks[],blanks[]\n",
    "    prompt = f\"A patient has an overall risk score of {ad_risk}, in the range of 0 to 1, of having Alzheimer's disease. \\\n",
    "    A multimodal deep learning model has attributed the high risk of Alzheimer’s disease to several salient features. \\\n",
    "    First, the {f1_name} with an attribution of {f1_atr}, and {f2_name} \\\n",
    "    (attribution of {f2_atr}), the {f3_name} (attribution of {f3_atr}), and {f4_name} \\\n",
    "    (attribution of {f4_atr}), {f5_name} (attribution of {f5_atr}), {f6_name} (attribution of {f6_atr}), \\\n",
    "    {f7_name} (attribution of {f7_atr}), and {f8_name} (attribution of {f8_atr}). \\\n",
    "    The patient has a {f1_name} {f1_sd} standard deviations {f1_hilo} than the general population. \\\n",
    "    A {f2_sd} standard deviations {f2_hilo} {f2_name}, {f3_sd} standard deviations \\\n",
    "    {f3_hilo} {f3_name}, and {f4_sd} standard deviations {f4_hilo} {f4_name} compared to the general population. \\\n",
    "    The patient scored {f5_sd} standard deviation {f5_hilo} in the {f5_name} compared to the general population. \\\n",
    "    The patient scored {f6_sd} standard deviations {f6_hilo} in the {f6_name}, {f7_sd} standard deviations {f7_hilo} {f7_name}, \\\n",
    "    and {f8_sd} standard deviation {f8_hilo} the {f8_name} compared to the general population. Explain how the salient features relate to one another \\\n",
    "    and how they relate to the higher risk of having Alzheimer’s disease. If any of those features is irrelevant to AD, please point it out.\"\n",
    "    return prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd_subtype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
